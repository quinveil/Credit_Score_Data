{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import statistics\n",
    "import imblearn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score,classification_report,confusion_matrix\n",
    "from scipy.stats import probplot\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, SVMSMOTE\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_original = pd.read_csv('Credit Score.csv')\n",
    "df_train = df_train_original.copy()\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe(exclude=np.number).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop kolom\n",
    "drop_columns = ['ID','Customer_ID','Name','SSN']\n",
    "df_train.drop(drop_columns,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop kolom karena outliers\n",
    "drop_columns = ['Amount_invested_monthly']\n",
    "df_train.drop(drop_columns,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Drop kolom karena multicolinearity\n",
    "# drop_columns = ['Annual_Income','Monthly_Inhand_Salary']\n",
    "# df_train.drop(drop_columns,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numericals = df_train.select_dtypes(include='number').columns.tolist()\n",
    "categorical = df_train.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "print(f\"Numerical columns are {numericals}\")\n",
    "print(f\"Categorical columns are {categorical}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#detail kolom \n",
    "def get_column_details(df,column):\n",
    "    print(\"Details of\",column,\"column\")\n",
    "    \n",
    "    #Tipe data\n",
    "    print(\"\\nTipe Data: \",df[column].dtype)\n",
    "    \n",
    "    #Kosong atau tidak ?\n",
    "    count_null = df[column].isnull().sum()\n",
    "    if count_null==0:\n",
    "        print(\"\\nTidak ada value yang kosong\")\n",
    "    elif count_null>0:\n",
    "        print(\"\\nAda \",count_null,\" null values\")\n",
    "        \n",
    "    #Get Number of Unique Values\n",
    "    print(\"\\nUnik: \",df[column].nunique())\n",
    "    \n",
    "    #Get Distribution of Column    \n",
    "    print(\"\\nDistribution of column:\\n\")\n",
    "    print(df[column].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mengisi missing value\n",
    "def fill_missing_with(df, column):      \n",
    "    print(\"\\nSebelum diisi:\",df[column].isnull().sum())\n",
    "    \n",
    "    df[column]=df[column].fillna(df[column].median())\n",
    "    \n",
    "    print(\"\\nSesudah diisi:\",df[column].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mengisi missing value dengan groupby\n",
    "def fill_groupby(df, column):\n",
    "    groupby='Occupation'      \n",
    "    print(\"\\nSebelum diisi:\",df[column].isnull().sum())\n",
    "    per_group = df.groupby(groupby)[column].transform(lambda x: x.mean())\n",
    "    df[column] = df[column].fillna(per_group)\n",
    "    print(\"\\nSesudah diisi:\",df[column].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_imputer(df, column):\n",
    "    if df[column].dtypes == object:\n",
    "        imputer = SimpleImputer(strategy='most_frequent')\n",
    "        df[column] = imputer.fit_transform(df[[column]])\n",
    "    else:\n",
    "        imputer = IterativeImputer()\n",
    "        df[column] = imputer.fit_transform(df[[column]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing(df, column):\n",
    "    #fill_groupby(df_train, column_name)\n",
    "    fill_missing_with(df_train, column_name)\n",
    "    #fill_imputer(df_train, column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label Encoding\n",
    "def ubah_label(df, column):\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "    categorical_columns = [column]\n",
    "    # Initialize the LabelEncoder\n",
    "    label_encoder = LabelEncoder()\n",
    "    df_train[column] = label_encoder.fit_transform(df_train[column])\n",
    "    print(label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regex(df, column, sampah=None,dummy=''):\n",
    "    if sampah!=None:\n",
    "        df[column] = df[column].replace(sampah,dummy)\n",
    "        print(f\"\\nSampah {sampah} is replaced with Blank\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#desimal Scaling\n",
    "def dec_scaling(df, column):\n",
    "    df[column] = df[column].values.reshape(len(df), 1)/100\n",
    "    df[column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pengolahan categorical\n",
    "def cat_process(df, column, sampah=None, dummy=''):\n",
    "    regex(df, column, sampah,dummy)\n",
    "    ubah_label(df, column)\n",
    "    #dec_scaling(df_train, column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#penanganan outliers menggunakan quantile\n",
    "def anti_outliers(df, column):\n",
    "    \n",
    "    Q1=df[column].quantile(0.25)\n",
    "    Q3=df[column].quantile(0.75)\n",
    "    IQR=Q3-Q1\n",
    "    print(Q1)\n",
    "    print(Q3)\n",
    "    print(IQR)\n",
    "    lower = Q1-1.5*IQR\n",
    "    upper = Q3+1.5*IQR\n",
    "        \n",
    "    df_train[column] = pd.DataFrame(np.where(df_train[column] >= upper, upper, \n",
    "        (np.where(df_train[column] <= lower, lower, df_train[column]))), columns=[column])\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.mstats import winsorize\n",
    "def anti_outliers_winsorize(df, column):\n",
    "    a=df[column]\n",
    "    df[column]=winsorize(a, limits=[0.1, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pengolahan Numerikal\n",
    "def num_process(df, column, strip=None, datatype=None, sampah=None):\n",
    "    #regex(df, column, sampah)\n",
    "    #ngresiki strip\n",
    "    if df[column].dtype == object and strip is not None:\n",
    "        df[column] = df[column].str.strip(strip)\n",
    "        print(f\"\\nTrailing & leading {strip} are removed\")\n",
    "        \n",
    "    #ganti datatype\n",
    "    if datatype is not None:\n",
    "        df[column] = df[column].astype(datatype)\n",
    "        print(f\"\\nDatatype of {column} is changed to {datatype}\")\n",
    "    anti_outliers(df_train, column_name)\n",
    "    #anti_outliers_winsorize(df_train, column_name)\n",
    "    #dec_scaling(df_train, column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot outlier\n",
    "def plot(df, column):\n",
    "    print(f\"Skewness of {column}:\",df[column].skew())\n",
    "    print(f\"Kurtosis of {column}:\",df[column].kurtosis())\n",
    "    plt.figure(figsize=(14,4))\n",
    "    plt.subplot(131)\n",
    "    sns.histplot(df[column])\n",
    "    plt.subplot(132)\n",
    "    sns.boxplot(df[column])\n",
    "    plt.subplot(133)\n",
    "    probplot(df[column],rvalue=True,plot=plt,dist='norm')\n",
    "    plt.suptitle(column)\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Credit Score\n",
    "column_name = 'Credit_Score'\n",
    "\n",
    "get_column_details(df_train, column_name)\n",
    "cat_process(df_train, column_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Occupation\n",
    "column_name = 'Occupation'\n",
    "sampah = '_______'\n",
    "\n",
    "cat_process(df_train, column_name,sampah)\n",
    "fill_missing(df_train, column_name)\n",
    "get_column_details(df_train, column_name)\n",
    "df_train\n",
    "df_train['Occupation'].isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Type_of_Loan\n",
    "column_name = 'Type_of_Loan'\n",
    "sampah = '_______'\n",
    "\n",
    "cat_process(df_train, column_name,sampah)\n",
    "fill_missing(df_train, column_name)\n",
    "get_column_details(df_train, column_name)\n",
    "df_train\n",
    "df_train['Type_of_Loan'].isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Credit_Mix\n",
    "column_name = 'Credit_Mix'\n",
    "sampah = '_'\n",
    "\n",
    "cat_process(df_train, column_name,sampah)\n",
    "fill_missing(df_train, column_name)\n",
    "get_column_details(df_train, column_name)\n",
    "df_train\n",
    "df_train['Credit_Mix'].isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Credit_History_Age\n",
    "column_name = 'Credit_History_Age'\n",
    "sampah = 'NA'\n",
    "\n",
    "def Month_Converter(val):\n",
    "    if pd.notnull(val):\n",
    "        years = int(val.split(' ')[0])\n",
    "        month = int(val.split(' ')[3])\n",
    "        return (years*12)+month\n",
    "    else:\n",
    "        return val\n",
    "    \n",
    "df_train['Credit_History_Age'] = df_train['Credit_History_Age'].apply(lambda x: Month_Converter(x)).astype(float)\n",
    "fill_missing(df_train, column_name)\n",
    "print(df_train['Credit_History_Age'])\n",
    "df_train['Credit_History_Age'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Payment_Of_Min_Amount\n",
    "column_name = 'Payment_of_Min_Amount'\n",
    "sampah = 'NM'\n",
    "\n",
    "cat_process(df_train, column_name,sampah)\n",
    "fill_missing(df_train, column_name)\n",
    "get_column_details(df_train, column_name)\n",
    "df_train\n",
    "df_train['Payment_of_Min_Amount'].isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Payment_Behaviour\n",
    "column_name = 'Payment_Behaviour'\n",
    "sampah = '!@9#%8'\n",
    "dummy = 'Unknown'\n",
    "\n",
    "cat_process(df_train, column_name,sampah,dummy)\n",
    "fill_missing(df_train, column_name)\n",
    "get_column_details(df_train, column_name)\n",
    "df_train\n",
    "df_train['Payment_Behaviour'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Month\n",
    "df_train['Month'] = pd.to_datetime(df_train.Month, format='%B').dt.month\n",
    "df_train['Month'].isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Age\n",
    "column_name = 'Age'\n",
    "\n",
    "num_process(df_train, column_name, strip='_', datatype=int)\n",
    "fill_missing(df_train, column_name)\n",
    "plot(df_train, column_name)\n",
    "df_train[df_train.Age <= 120].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multicolinear\n",
    "#Annual Income\n",
    "column_name = 'Annual_Income'\n",
    "\n",
    "num_process(df_train, column_name, strip='_', datatype=float)\n",
    "fill_missing(df_train, column_name)\n",
    "plot(df_train, column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multicolinear\n",
    "#Monthly_Inhand_Salary\n",
    "column_name = 'Monthly_Inhand_Salary'\n",
    "\n",
    "num_process(df_train, column_name, strip='_', datatype=float)\n",
    "fill_missing(df_train, column_name)\n",
    "plot(df_train, column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Num_Bank_Accounts\n",
    "column_name = 'Num_Bank_Accounts'\n",
    "\n",
    "num_process(df_train, column_name, strip='_', datatype=int)\n",
    "fill_missing(df_train, column_name)\n",
    "plot(df_train, column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Num_Credit_Card\n",
    "column_name = 'Num_Credit_Card'\n",
    "\n",
    "num_process(df_train, column_name, strip='_', datatype=int)\n",
    "fill_missing(df_train, column_name)\n",
    "plot(df_train, column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Interest_Rate\n",
    "column_name = 'Interest_Rate'\n",
    "\n",
    "num_process(df_train, column_name, strip='_', datatype=int)\n",
    "fill_missing(df_train, column_name)\n",
    "plot(df_train, column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Num_of_Loan\n",
    "column_name = 'Num_of_Loan'\n",
    "\n",
    "num_process(df_train, column_name, strip='_', datatype=int)\n",
    "fill_missing(df_train, column_name)\n",
    "plot(df_train, column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delay_from_due_date\n",
    "column_name = 'Delay_from_due_date'\n",
    "\n",
    "num_process(df_train, column_name, strip='_', datatype=int)\n",
    "fill_missing(df_train, column_name)\n",
    "plot(df_train, column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Num_of_Delayed_Payment\n",
    "column_name = 'Num_of_Delayed_Payment'\n",
    "\n",
    "num_process(df_train, column_name, strip='_', datatype=float)\n",
    "fill_missing(df_train, column_name)\n",
    "plot(df_train, column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changed_Credit_Limit\n",
    "column_name = 'Changed_Credit_Limit'\n",
    "sampah = '_'\n",
    "regex(df_train, column_name, sampah)\n",
    "df_train['Changed_Credit_Limit']=pd.to_numeric(df_train['Changed_Credit_Limit'], errors='coerce')\n",
    "num_process(df_train, column_name,  strip='_',datatype='float')\n",
    "fill_missing(df_train, column_name)\n",
    "plot(df_train, column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Num_Credit_Inquiries\n",
    "column_name = 'Num_Credit_Inquiries'\n",
    "\n",
    "num_process(df_train, column_name, strip='_', datatype=float)\n",
    "fill_missing(df_train, column_name)\n",
    "plot(df_train, column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outstanding_Debt\n",
    "column_name = 'Outstanding_Debt'\n",
    "\n",
    "num_process(df_train, column_name, strip='_', datatype=float)\n",
    "fill_missing(df_train, column_name)\n",
    "plot(df_train, column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Credit_Utilization_Ratio\n",
    "column_name = 'Credit_Utilization_Ratio'\n",
    "\n",
    "num_process(df_train, column_name, strip='_', datatype=float)\n",
    "fill_missing(df_train, column_name)\n",
    "plot(df_train, column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total_EMI_per_month\n",
    "column_name = 'Total_EMI_per_month'\n",
    "\n",
    "num_process(df_train, column_name, strip='_', datatype=float)\n",
    "fill_missing(df_train, column_name)\n",
    "plot(df_train, column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #note : didrop karena outliers\n",
    "# #Amount_invested_monthly\n",
    "# column_name = 'Amount_invested_monthly'\n",
    "\n",
    "\n",
    "# num_process(df_train, column_name, strip='_', datatype=float)\n",
    "# fill_missing(df_train, column_name)\n",
    "# plot(df_train, column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Monthly_Balance\n",
    "column_name = 'Monthly_Balance'\n",
    "\n",
    "num_process(df_train, column_name, strip='_', datatype=float)\n",
    "fill_missing(df_train, column_name)\n",
    "plot(df_train, column_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Multicolinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "feature = df_train.drop(columns='Credit_Score')\n",
    "target = df_train[['Credit_Score']]\n",
    "\n",
    "feature_cs_train, feature_cs_test, target_cs_train, target_cs_test = train_test_split(feature, target, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pengecekan VIF (variance inflation factor)\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor as vif \n",
    "from statsmodels.tools.tools import add_constant\n",
    "\n",
    "X=add_constant(feature_cs_train)\n",
    "\n",
    "vif_df=pd.DataFrame([vif(X.values, i)\n",
    "                     for i in range(X.shape[1])],\n",
    "                    index=X.columns).reset_index()\n",
    "vif_df.columns=['feature','vif_score']\n",
    "vif_df=vif_df.loc[vif_df.feature!='const']\n",
    "vif_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.to_excel('creditscore_output.xlsx', engine='xlsxwriter')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split Input & Output Data\n",
    "X = df_train.drop('Credit_Score',axis=1)\n",
    "y = df_train['Credit_Score']\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE() # Synthetic Minority Oversampling TEchnique\n",
    "X, y = smote.fit_resample(X,y)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize Data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler2 = StandardScaler()\n",
    "X = scaler2.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split Data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Klasifikasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method to evaluate the performance of the model\n",
    "def evaluate_model(y_test,y_pred):\n",
    "    print(\"Classification Report\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Create a heatmap of the confusion matrix using Seaborn\n",
    "    sns.heatmap(cm, annot=True, cmap='Greens',fmt='.0f')\n",
    "\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.title('Confusion Matrix')\n",
    "\n",
    "    plt.show()\n",
    "    jclass = len(np.unique(y_test))\n",
    "    tp = np.zeros(jclass)\n",
    "    tn = np.zeros(jclass)\n",
    "    fp = np.zeros(jclass)\n",
    "    fn = np.zeros(jclass)\n",
    "    for kelas in range(jclass):\n",
    "        tp[kelas] = cm[kelas,kelas]\n",
    "        fn[kelas] = np.sum(cm[kelas, :]) - tp[kelas]\n",
    "        fp[kelas] = np.sum(cm[:, kelas]) - tp[kelas]\n",
    "        tn[kelas] = np.sum(cm)-tp[kelas]-fn[kelas]-fp[kelas]\n",
    "    df_train=pd.DataFrame({'Kelas ': np.unique(y_test), 'TP' : tp, 'TN': tn, 'FP': fp, 'FN': fn })\n",
    "    specificity = tn/(tn+fp)\n",
    "    avg_specificity = specificity.mean()\n",
    "    print(df_train)\n",
    "    print(f'Average Specificity : {avg_specificity}')\n",
    "    \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#klasifikasi dan evaluasi\n",
    "classifiers = [('KNN',KNeighborsClassifier(n_neighbors=17)), ('Decision Tree',DecisionTreeClassifier())]\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# Calculate average performance metrics\n",
    "for model, clf in classifiers:\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    akurasi = accuracy_score(y_test, y_pred)\n",
    "    presisi = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f_score = 2 * (presisi * recall) / (presisi + recall)\n",
    "\n",
    "        \n",
    "        \n",
    "    # Print the performance metrics\n",
    "    print(f'Classifier: {model}')\n",
    "    evaluate_model(y_test, y_pred)\n",
    "    print(f'Accuracy: {akurasi}')\n",
    "    print(f'Precision: {presisi}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print(f'F score: {f_score}')\n",
    "    print('------------------------------------------------------------')\n",
    "    print('------------------------------------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "350ec87d84c6c58898f5c2e4bbb3396f5f55fe152cf4ea5d1a9ddc7ca48985be"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
